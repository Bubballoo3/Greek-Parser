{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYXRFFDa6zH1EzgQFnccJo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bubballoo3/Greek-Parser/blob/main/Final_Project_Greek_Parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Ancient Greek Helper\n",
        "A tool that is able to reference conjugation/declension tables and dictionary entries in order to parse and define ancient greek words just like a real classicist."
      ],
      "metadata": {
        "id": "eiS2oYn4GyLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the moment, this is restricted to standard attic forms. With more tables, this restriction could be widened in the future"
      ],
      "metadata": {
        "id": "5NO60hbnJdnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load auxillary files from github and change directories\n",
        "\n",
        "!git clone https://github.com/Bubballoo3/Greek-Parser.git\n",
        "import os\n",
        "os.chdir(\"Greek-Parser\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esmmw5jBpEQ6",
        "outputId": "915091c9-b7de-49dc-e29e-05a1bda30201"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Greek-Parser'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 139 (delta 85), reused 118 (delta 76), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (139/139), 1.49 MiB | 14.21 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wK2SBWnToPYc",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Install langraph\n",
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_openai\n",
        "# Install Gradio\n",
        "!pip install gradio==3.38.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The packages and setup are drawn from the LangGraph tutorial [here](https://langchain-ai.github.io/langgraph/tutorials/introduction/#setup)"
      ],
      "metadata": {
        "id": "baYivUTbIX8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import getpass\n",
        "import os\n",
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.messages import AIMessage\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode\n",
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Get API key for openAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "from langchain_openai import ChatOpenAI\n"
      ],
      "metadata": {
        "id": "dewEsffupKGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8e915c7-c3e2-474a-a41b-fb28844e34a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Then we define our llm\n",
        "llm=ChatOpenAI(model_name=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "NsOZgqI8IGdX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the pieces in place for LangGraph, we begin to make the individual agents involved.\n",
        "\n",
        "The first one will check for an entry in LSJ. Ensure that the lsj.json file is uploaded to the current colab session"
      ],
      "metadata": {
        "id": "n03Ra70fJhY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "@tool\n",
        "def checkLSJ(string: str):\n",
        "    \"\"\"Search the Liddel and Scott Greek-English Lexicon for a specific word\n",
        "\n",
        "       It returns a (python) dictionary with two keys, \"definition\" and \"mention\" with list values.\n",
        "\n",
        "       The \"definition\" list holds at most one dictionary entry and is focused on that word.\n",
        "\n",
        "       The \"mention\" list holds all the places where the searched word was mentioned in the definition of a different word.\"\"\"\n",
        "    results={\"definition\":[],\"mention\":[]}\n",
        "    with open('./resources/lsj.json', 'r') as file:\n",
        "        data = json.load(file)\n",
        "    for key, value in data.items():\n",
        "        response_type = \"none\"\n",
        "        if key == string:\n",
        "            response_type = \"definition\"\n",
        "        else:\n",
        "            for smkey, smvalue in value.items():\n",
        "                if smkey == 'd':\n",
        "                    if string in smvalue:\n",
        "                        response_type = \"mention\"\n",
        "                elif isinstance(smvalue, list):\n",
        "                    for item in smvalue:\n",
        "                        if string == item:\n",
        "                            response_type=\"definition\"\n",
        "        if response_type != \"none\":\n",
        "            if len(results[response_type]) < 5:\n",
        "                results[response_type].append(value['d'])\n",
        "    if len(results) > 0:\n",
        "        return results\n",
        "    else:\n",
        "        return \"Not found\""
      ],
      "metadata": {
        "id": "PPX6gu-3JxqU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect tools and create tooled LLM\n",
        "tools = [checkLSJ]\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "6QCpMjN8p61s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models\n",
        "def translator(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}"
      ],
      "metadata": {
        "id": "wMbTypYQqrN5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then define our graph. As a single agent system, this is pretty simple. More or less it is\n",
        "```\n",
        "     START\n",
        "       |\n",
        "       |\n",
        "      \\|/            (If tool calls)\n",
        "  Translator Agent  ------------------>    Tool Node\n",
        "       |         /|\\                           /\n",
        "       |          \\_________________________/\n",
        "       |\n",
        "       | (If no tool calls or errors occur with the tools)\n",
        "       |\n",
        "      \\|/\n",
        "      END                                            \n",
        "```\n",
        "As such we have to create the translator and tool_node nodes first, and then create the edges. The only complicated edge are the two leaving the translator, which are controlled using a conditional edge, and decides which edge to follow."
      ],
      "metadata": {
        "id": "nowGhvxdXHDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define nodes and graphs\n",
        "graph_builder = StateGraph(State)\n",
        "tool_node = ToolNode(tools)\n",
        "graph_builder.add_node(\"translator\",translator)\n",
        "graph_builder.add_node(\"tool_node\",tool_node)\n",
        "graph_builder.add_edge(START, \"translator\")\n",
        "\n",
        "# The route_tools function decides when to send an AI response to a tool, and when to finish\n",
        "def route_tools(state: State):\n",
        "    \"\"\"Use in the conditional_edge to route to the tool_node if there are tool calls\"\"\"\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "    lastmessage=state[\"messages\"][-2]\n",
        "    if hasattr(messages[-2],\"status\") and \"Error:\" in messages[-2].content:\n",
        "        return END\n",
        "    elif hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"translator\",\n",
        "    route_tools,\n",
        "    {\"tools\":\"tool_node\",END:END},\n",
        ")\n",
        "graph_builder.add_edge(\"tool_node\", \"translator\")\n",
        "\n",
        "graph=graph_builder.compile()"
      ],
      "metadata": {
        "id": "p-NWrjtKq_eq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then write a function to interact with the graph. We give a precise workflow in the system instructions and a one-shot prompt to ensure proper formatting."
      ],
      "metadata": {
        "id": "JWHlXkrtudmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We then access a stream of messages from a graph instance.\n",
        "#searchword = input(\"Enter a word to search for: \")\n",
        "def gradiointeract(searchword):\n",
        "    events=graph.stream({\"messages\": [(\"system\",\"\"\"\n",
        "        You are a classicist skilled in Ancient Greek and interpreting entries and abbreviations from the LSJ Greek-English Lexicon.\n",
        "        When given a word (the word will not have accents, be prepared for this), you first use the checkLSJ tool to check if that word exists as an entry. The following\n",
        "        rules should help you parse these dictionary entries.\n",
        "        1. Words in <b> brackets are the title of the entry. When you search, you may get an entry with your word in <i> brackets, in which case you should use the context to help you find the right word.\n",
        "        2. If the entry contains \"v.\" followed by a different word, it is a referral to a different word and you should search that word and show the result.\n",
        "\n",
        "        After searching the dictionary, use the result to interpret and parse the word.\n",
        "        If you can't find direct results, see if you know the root word. If not, guess what part of speech it is and what conjugation/declension it is. From there, try to approximate the dictionary form (nominative singular for nouns, first person singular present active for verbs). Continue to search the dictionary until you find the entry for the root word. The root word should always be in the dictionary, and you should access the definition before finishing.\n",
        "        Note that the same word has many different forms in greek, so you will likely have to convert it either to the nominative singular (for nouns), the nominative\n",
        "        masculine singular (for adjectives), or the first person present active indicative (for verbs). When you are done you should give a description of the process you used to get the form, then give your parse of the word, and quote the FULL dictionary definition EXACTLY QUOTED FROM LSJ of the root word, and add newlines when appropriate. Make sure you always provide your parsing and quote the final entry in its entirety. NEVER simulate an entry you did not look up.\n",
        "\n",
        "        REMEMBER!! You must include the full parsing of the searched word and definition of the root word in every answer. Acknowledge when you do not think you are correct.\"\"\",),\n",
        "                                (\"user\",\"ελθουσα\"),\n",
        "                                (\"assistant\",\"\"\"\n",
        "    The word \"ελθουσα\" is a form of the verb \"ἔρχομαι,\" which means \"to come\" or \"to go.\" In this case, \"ελθουσα\" is a feminine participle, specifically the aorist active participle form. To understand its meaning and grammatical properties, I checked the root entry for \"ἔρχομαι,\" as well as the aorist participle form \"ἐλθών.\"\n",
        "\n",
        "    ### Parsing Process:\n",
        "    1. **Identify the root**: The word \"ελθουσα\" derives from the verb \"ἔρχομαι\" (to come/go), specifically from its aorist stem.\n",
        "    2. **Determine the form**: The suffix \"-ουσα\" indicates that it is a feminine aorist active participle in the nominative singular form.\n",
        "    3. **Check for definitions**: Upon checking \"ἔρχομαι,\" I found that it indeed relates to \"ελθουσα,\" which corresponds to the aorist active participle form \"ἐλθών\" for masculine and \"ελθουσα\" for feminine.\n",
        "\n",
        "    ### Parsed Form:\n",
        "    - **Word**: ελθουσα\n",
        "    - **Root**: ἔρχομαι\n",
        "    - **Form**: Aorist active participle, feminine singular nominative\n",
        "    - **Meaning**: \"having come\" or \"having gone\"\n",
        "\n",
        "    ### Definition from LSJ:\n",
        "    The entry for \"ἔρχομαι\" describes it as follows:\n",
        "\n",
        "    > \"<b>ἔρχομαι</b> Il.13.256, etc. (Act. <i>ἔρχω</i> as barbarism, Tim.Pers.167): impf. <i>ἠρχόμην</i> Hp.Epid.7.59, Arat.102, (<i>δι-</i>) Pi.O.9.93; freq. in later Prose, LXXGe.48.7, Ev.Marc.1.45, Luc.Jud.Voc.4, Paus.5.8.5, etc.; in Att. rare even in compds., <i>ἐπ-ηρχόμην</i> Th.4.120 (perh. fr. <i>ἐπάρχομαι</i>), <i>προσ-</i> ib.121 (perh. fr. <i>προσάρχομαι</i>), <i>περι-</i> Ar.Th.504 cod.: from <i>ἐλυθ-</i> (cf. <i>ἐλεύθω</i>) come fut. <i>ἐλεύσομαι</i>, Hom., Ion., Trag. (A.Pr.854, Supp.522, S.OC1206, Tr.595), in Att. Prose only in Lys.22.11, freq. later, D.H.3.15, etc.: aor., Ep. and Lyr. <i>ἤλῠθον</i> Il.1.152, Pi.P.3.99, etc., used by E. (not A. or ) in dialogue (Rh.660, El.598, Tr.374, cf. Neophr.1.1); but <i>ἦλθον</i> is more freq. even in Hom., and is the only form used in obl. moods, <i>ἐλθέ</i>, <i>ἔλθω</i>, <i>ἔλθοιμι</i>, <i>ἐλθεῖν</i>, <i>ἐλθών</i> [...]\"\n",
        "    \"\"\"),\n",
        "                                (\"user\",f\"{searchword}\")\n",
        "    ]})\n",
        "\n",
        "    lastmessage = \"\"\n",
        "    for event in events:\n",
        "        for value in event.values():\n",
        "            message=value[\"messages\"][-1].content\n",
        "            if len(message) > 0:\n",
        "                lastmessage = message\n",
        "    return lastmessage"
      ],
      "metadata": {
        "id": "wAAbbhHqtChY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add Gradio\n",
        "import gradio as gr\n",
        "\n",
        "interface = gr.Interface(fn=gradiointeract,\n",
        "                         inputs=gr.Textbox(lines=1, placeholder=\"Enter a word to search for\"),\n",
        "                         outputs=gr.Markdown(),\n",
        "                         title=\"Ancient Greek Parser\",\n",
        "                         )\n",
        "\n",
        "interface.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "IexHEZe2tmxj",
        "outputId": "dbc7517d-4a9f-428b-c26f-1d6ff7050872"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "IMPORTANT: You are using gradio version 3.38.0, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://efbcb0afd06e65be71.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://efbcb0afd06e65be71.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://efbcb0afd06e65be71.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}